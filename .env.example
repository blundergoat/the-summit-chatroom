# =============================================================================
# .env.example — Environment variables for The Summit
# =============================================================================
#
# Copy this file to .env and customize it:
#   cp .env.example .env
#
# This file is read by BOTH:
#   - Symfony (APP_*, AGENT_ENDPOINT, MERCURE_*)
#   - Docker Compose (MODEL_PROVIDER, OLLAMA_MODEL, MERCURE_JWT_SECRET, AWS_*)
#
# When running via Docker Compose, container-level environment variables in
# docker-compose.yml OVERRIDE values from this file for the services that
# define them (e.g. AGENT_ENDPOINT is overridden to http://agent:8000).
# =============================================================================

# ============================================================
# Symfony Application
# ============================================================
# APP_ENV    — "dev" enables debug mode (detailed error pages, debug toolbar)
# APP_DEBUG  — "1" enables the Symfony debug toolbar and profiler
# APP_SECRET — A secret used for CSRF tokens and session signing.
#              MUST be changed in production!
# AGENT_ENDPOINT — URL of the Python agent.
#   Local dev: http://localhost:8081 (default — used by start-dev.sh)
#   Docker:    http://agent:8000 (overridden in docker-compose.yml automatically)
#
# NOTE: The PHP built-in server (used by start-dev.sh) does NOT pass shell
# environment variables into PHP's $_SERVER/$_ENV. Symfony's DotEnv reads
# this file directly, so the value here IS what Symfony uses in local dev.
# Docker Compose overrides it via its own environment: block.
APP_ENV=dev
APP_DEBUG=1
APP_SECRET=the-summit-dev-secret-change-me
AGENT_ENDPOINT=http://localhost:8081

# ============================================================
# Model Provider — choose "ollama" (local) or "bedrock" (AWS)
# ============================================================
MODEL_PROVIDER=ollama

# --- Ollama settings (used when MODEL_PROVIDER=ollama) ---
# No credentials needed. Model is pulled automatically on first run.
# OLLAMA_HOST — Where the Ollama server is listening.
#   Native Linux:  http://localhost:11434 (default)
#   WSL2 with GPU: http://localhost:11435 (set by scripts/install-ollama.sh)
#   The WSL install uses port 11435 to avoid conflicts with Windows Ollama.
#OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen2.5:14b
# Other good options: qwen2.5:7b (faster on CPU), mistral, llama3.1, gemma2


# --- Bedrock settings (used when MODEL_PROVIDER=bedrock) ---
# Uncomment and fill in to use AWS Bedrock instead of Ollama:
# MODEL_PROVIDER=bedrock
# AWS_ACCESS_KEY_ID=your-access-key-id
# AWS_SECRET_ACCESS_KEY=your-secret-access-key
# AWS_DEFAULT_REGION=ap-southeast-2
# MODEL_ID=us.anthropic.claude-sonnet-4-20250514-v1:0

# ============================================================
# Mercure — Real-time streaming
# ============================================================
# JWT secret shared between the PHP app and the Mercure hub.
# MUST be at least 32 characters (256 bits) for HS256 signing.
#
# start-dev.sh will auto-start a Mercure Docker container when
# MERCURE_URL is set. Leave URL/PUBLIC_URL empty to disable
# streaming (sync mode only).
#
# Docker Compose overrides URL/PUBLIC_URL automatically.
MERCURE_JWT_SECRET=the-summit-mercure-dev-secret-key
MERCURE_URL=http://localhost:3100/.well-known/mercure
MERCURE_PUBLIC_URL=http://localhost:3100/.well-known/mercure
